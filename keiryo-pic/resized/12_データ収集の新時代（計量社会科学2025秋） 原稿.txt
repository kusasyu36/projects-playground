
話者 1 00:00 
プロジェクターの調子があまり今良くないので、資料自体は今日あのアップロードしてありますので、そちらをダウンロードしていただいてご覧いただければというふうに思います。 で、今日の内容に入る前に、前回のリプライですね。 について触れておきたいというふうに思います。

前回は近年回収率というものが下がっていて困りますなという話をしたところで、では回収率というものはどのようにすれば上がるんでしょうかということを藁にもすがる思いで皆さんに聞いたというのが前回の内容でありました。 これに関してはいろんな提案をなさっていただいたりとかですね、そういうことはあんまり考えてこなかったなとかっていうことを、いろいろ私も学ぶことが大きかった。 多かったんですけれども、例えばですね、対象者にフィードバックをするっていうことの重要性を指摘されている方がいらっしゃいました。 まああの、そうですね、こういうのは大きな全国調査、私たちもやってますけれども、一定程度規模の大きな全国調査等では、調査の結果こういうことがわかりましたっていうことを簡単なですね、リーフレットにまとめるなりなんなりと、お金がない場合はウェブサイトにちょっと上げて、あげるってだけですけれども。 調査速報だとかですね。 あるいはノンテクニカルな内容、あんまりこう数式とか出すと大体みんな嫌がりますから。 グラフでちょっと分かりやすく、こういうことが分かりましたっていうことを発表するっていうようなことなんかやったりしたりすることもありません、あるんですけれども。 そこからまあどの程度ですね、関心を持ってもらえるかっていうことは未知数な部分もあるというところですね。 これも次回ちょっとお話しする、その調査技術の関連で言っても、フィードバックっていうのが必要な面もあるんですけれども。 回収率への貢献という点でいうと、この点に関しては内容にもよるんでしょうけれども、難しいところもあるかもしれないというものです。

で、質問数を減らした方がいい、質問数は少ない方が良いというふうに指摘された方もいらっしゃって、それは全くその通りであります。 で、調査票が長いと回収率が下がるということはもう 50年近く前ですね。 これは僕はこの人たちあんまり読んであげませんけれども。 アメリカンソシオロジカルレビューという。 アメリカンソシオロジカルレビューっていうのがあったような。 そうですね。 アメリカンソシオロジカルレビューという社会学におけるトップジャーナルの一つでありますけれども、その論文の中で、いろんな回収率に影響を与えそうないろんな要因と回収できたかどうかということを予測するモデルを推定しているというような、ずいぶん昔の論文ですけど、そこで言われていることが大体今でも通用するっていうような感じですね。 古くから知られています。 もちろんその長い場合でも、こういう場合、こういう条件のもとでは回収率はそれほど下がらないとか、まあ細かい話はいろいろあるかもしれませんけれども、大まかな、いわゆる主効果としての調査票の長さというものは、回収率を下げるというのはほぼ確実だと言っていいと思います。 まあ、なんでかって、それはそんな難しい話ではなくて、面倒くさそうに見えるものはやりたくないっていうものですね。 で、インセンティブを設けるってこともご提案される方がいらっしゃいました。 謝礼による動機づけっていうものだとか、あとは興味関心を喚起するという、これはインセンティブっていうよりは動機づけってことなんでしょうけれども。 そういうことに努力する調査の重要性とか面白さみたいなもの、そのトピックの面白さみたいなものを。 えーっと、とととととととととととと、そういうものを紹介とか、もっとこう工夫すべきだっていうふうに言われる。 それはその通りなんですけれども。 私が関わっているような調査というのは、比較的働き方とかキャリア形成とか人間関係とか、あるいはより一般的なですね、生活一般に関する調査であれば、ちょっと面白そうなトピックとかを入れるということも可能かもしれませんが、テーマによっては難しいかもしれませんね。 例えば、差別された経験、差別した経験について調査したいという、これは社会科学的にも、あるいは場合によっては行政にとってもすごく大事なテーマになるんですけれども。 あんまりそういうので前回紹介したパネルみたいなパパパパパパパ飛んでるとちょっとなんかウィアードな感じがしてきますよね。 なので、比較的センシティブなテーマで調査をやるという場合には、まあなんていうか、あの、面白いですよっていうのもなかなか難しいところがあるのかなというふうに思います。

で、結構な人たちが社会調査の認証機関みたいなものがあればいいんじゃないかみたいなことをおっしゃっておられましたが、認証制度っていうのは今のところありません。 これについては後でまたちょっと触れておきたいと思います。 あと、広告宣伝というものをおっしゃる方もいて、我々もそういうのは考えてはいるんですけれども、私たちが調査をやるときにも。 なんか芸能人とか何か吉本と東大は一応協定を結んでいるので、そんな高くない芸人さんとか使えないかなとかって思ったりすることあるんですが。 ただ、科学研究費補助金で吉本興業の人を雇って、やっとうというか、そういう人たちにギャラを払って調査の報告費に使うとなんか後々いろいろ言われそうだなという気もして、難しいなという感じなんですけれども。 これは科研費で使っていいのかどうかっていうのが非常に困ったなというところではあるんですが。 まあ、ただ、 YouTuber とかその他インフルエンサーというものに、をなんかうまく使うっていうのは、確かに今後考えていかなければならないんだろうし。 政府の統計調査ですね。

国勢調査なんかはそうやってタレントさんとか使ってるわけですよね。 今年は松平健さんが登場してたわけですけれども。 で、あと回答負担を減らすっていうのは、これは質問数を減らすというのと同じよう、同様で、例えばレイアウトを工夫する、答えやすいレイアウトを心がけるっていう回答意欲を削がないようなレイアウトとか、あるいは文字のサイズとかですね、あのー、或いは強調、強調、太字とか下線を引いて強調するとかですね、そういう細かいところでの努力も必要になってくるだろうということが考えられるということですね。 今日もちょっと内容が多いのでサクサクいきますが。 えー、協力者を増やすると回答が雑になってしまうんじゃないかというのは、これは理屈で考えれば協力しやすい調査が真面目にやってくれるだろうと考えられると思うので、本来は正確になるはずなんですけれども。 ただ、その協力しやすさを高めるあまりに、むしろ何か適当に答えてもいいからすぐに謝礼をもらおうみたいな形になってしまうと、確かに雑になっちゃうかもしれないという点がありますね。

で、あとこれは認証機関問題ですね。 で、まあ確かにそうちゃそうなんですが、そもそも認証機関から認定を受けて行っている調査ですっていうことを書いて、一体対象者の人たちはそれをそうかそうかと思ってくれるのかどうかということですね。 で、まあ確かに政府とか総務省統計局が OK って言ってましたって言ったら、まああのー答えた方がいいのかなと。 どちらかというとそれは調査の質がいいというよりは、なんか総務省統計局みたいな政府の名前が入ってると、答えないとなんか後で良くないことが起こるのかなっていうふうに、割とこう権力的な作用を発生させているような気もしますけれども。 

話者 1 08:38 
まあ実際ですね、えっと、まああの、私が数少ない経験で言えば、中国で調査をやろうとしたときには、中国の統計局に認可オッケーをもらわなければならず。 えー、まああの、えーと、ちゃんと拒否されたっていう、そういう経験があります。

で、えーと、この政府が認証するっていうのは、確かに非常にですね、あの説得力が出てくるんですけれども。 何だかんだ言って日本に暮らしてる人たちは権威主義的なんで、行政とか政府が言うんだったらということで協力する人たちがいるでしょうけれども。 じゃあ政府が認証を与える、与えないという判断をするということになると、ちょっと警戒しなければならないのは、調査内容をどこまでチェックするんですかということが問題となってくるわけです。 で、当然ながら政府が行う、あの、前の会とかでちょっと言った一般統計調査をするときには、総務省統計局チェックというのも入って、当然そこでこれってなんで聞かなきゃいけないの？ みたいな話が出てきて、聞けないということも当然出てくるわけです。 で、政府が認証する場合は調査内容には立ち入らないことを担保させる必要があるわけですね。 あの、例えば私のような社会科学系の人間だと、時に政府に都合の悪いことを調べようとするということもあるわけです。 えー、まあ、あの、例えばどっかで言ったかも、別の種類か。 日本国政府は今のところ日本には移民はいないというふうな態度をずっと取り続けているわけですけど、じゃあ私が移民、日本で暮らす移民について調査したいですっていう調査企画を立てた場合に、デザインをバッチリ、工学も海外で行われている研究成果みたいなのを踏まえて、ちゃんと学術的にはしっかりしている。 で、設計もしっかりしているって言うんだけれども、いや、日本には移民がいないんでって言われて、もし却下されたらどうなりますかっていうことですね。 この政府に都合の悪いことを調べるっていうことが、政府の認証を得る場合にはなかなか難しいと考えると、研究の自由、調査の自由という、ある意味ですごく民主主義にとって重要なことだと思いますけれども。 それができないってなってしまうと、あるいはそれを犠牲にしてでも政府の認証を受けなきゃいけないっていうことになってしまうと、なかなか厳しいのかなというふうにも思います。

現にですね、教育の研究をしている人たちなんかは、学校を通して保護者などに調査を行ったりするわけですけれども、そうすると大概の場合、学校チェックが入るわけですね。 学校チェックが入ると、学校当時の調査で親の職業とか年収とかっていうのは大体はねられます。 そういうことを聞かないでくれというふうに言われるわけです。 まあ、教務員側が聞きたくないというよりは、学校通しで調査をやったときに、なんで保護者の方から学校にクレームがいくということで、いろいろもめるということですね。 はい。 で、えー、なのでなかなか第三者をかますのは結構、とりわけその権力的な作用を及ぼすことができるような。 主体を認証機関にする場合には、あのー、割とセンシティブに慎重に考えなければならないことがあるということですね。 じゃあ学会でいいじゃんということなんですけれども、ただ学会だったら、私だったら私が全部決めていいって言うんだったら、こんな調査もういらないからやらないでくださいとか、こんなものは素敵データファイルからダウンロードできるんで、そっち使ってくださいとかいうふうに、バンバン私は仕切っていきますけども。 ただ、そういうのが嫌な人たちもいるわけですね。 そういうのが嫌な人たちが恐らくもめるっていうことになって、もめること自体は別に止められないわけです。 私は別に何か、あの、その人たちを学会から追い出すことができませんので、なかなか難しいのかな、課題は大きいなというふうに思います。

で、地域の経済状況などによって社会調査の回収率が異なるのかという質問でしたが、えーと結論から言うと、ちょっと答えはぱっとは得られませんでしたというか。 まず、発展途上国どのあたりのことを想定するかにもよるんですが、発展途上国で確率抽出の調査というと多分なかなか難しいとか、あるいは権威主義体制の国で確率抽出標本の調査を行うのはなかなか難しいと、そういうところに、その、いわゆる権力主体じゃない普通の人間がアクセスして、ランダムサンプリングするってこと自体が、おそらくはあまり許容されないので、そもそも調査できるんだろうかというところがあるんですが。 近いところでですね、ヨーロピアンソーシャルサーベイという国際比較調査があります。 EU 圏内、なんでユナイテッドキングダムもいるんだろうねとかと思いますけど、まあいいでしょう。 えーと、 UK を含めてですね、ヨーロピアンソーシャルサーベイというものが行われまして、ヨーロッパの国々を比較ができるようなデザインで調査をやっていることがあります。 で、この回収率ですね。 を見ると、ちょっと画面だと見えづらいかもしれませんが、青線が全体の多分回収いや、そんなに高くないと思う。 あ、これ他人の調査なのかな、ちょっとわかんないけれども。 青線が全体の平均で当然そこから高かったり低かったりするということがあります。 で、経済発展度合いではおそらく説明が難しくて、例えば人口の流動性、つまり人があの本当に短期間で、いろいろ移動しちゃうような地域だと、あの、えーと、なんか何回か前半ぐらいのところで行った、いわゆる不適格事例がたくさん発生しちゃったりするわけですね。 えー、あの要は訪ねていったらいなかったとかっていうケースがたくさん出てきてしまったりすると、やっぱり回収率そのものは下がってきちゃうし、そもそも調査も出にくくなりますね。 あるいは信頼できる標本抽出台帳が利用できるかどうかという点も重要で、あの、本当に日本のですね、住民基本台帳とか選挙人名簿の閲覧ができるというのは、これは社会科学の研究にとってはすごく大事なものですね。 大事なあの何て言うか調査上の条件だったりします。 こうした信頼できる台帳が利用できるとか、あるいは人口の流動性がそれほど高くない、地理的な意味でのですね、流動性がそれほど高くないことによって、対象者の接触を安定的に維持できるということの方がもしかすると重要かもしれないということですね。 これはまあ、いろこのご質問については、何か単一の方法で何か評価ができるというよりは、まあいろんなことを試して結果が変わらなければ、そうなんだろうというふうに判断するというのが研究の実際かなというものですね。

で、協力率を高める工夫が回答内容のバイアスを生む可能性ということについては、まあこれも多分ケースバイケースですね。 例えば、あの回収率を上げるっていう点で調査に対する興味関心を高めてもらうっていうのは、大事な工夫かとは思うんですけど。 むしろそれですごく調査の調査事項について興味関心を持ったり、あれこれ考えながら、まあいいことなんですけど、協力してくれた結果、そうしない時と比べると、例えばある特定の何か政策とか意見に対して、そういう何かいろいろ刺激を受けなければ、何かよくわかんねーやって言ってわからないとか無回答というふうに答えてた人たちが突然目覚めちゃって、賛成とか反対とかっていうふうに答え始めるってなっちゃうと、どっちがいいのかはちょっとわかりませんね。 っていうことですね。 ようわからんわっていう方がもしかすると実態かもしれないわけですから。 例えばそういう可能性もあるだろうし、あるいは高額な謝礼を渡すことによってラッキーと思った結果、生活満足度が上がる可能性だってあり得るわけですね。 

話者 1 16:50 
なので、何とも言えないということで、いろいろ試すと面白いのかなというふうには思います。 で、このご指摘については、これは調査現場では経験値として実践されています。 なかなか回収しづらい層については、アタックを積極的に行うといったようなことなんかは試されています。 もちろん、これはたくさん接触した人とそんなに接触せずに回答してくれた人の間では違いがありそうっちゃありそうなんだけれども。 まあただ、やっぱり回収率はそれなりに高い方が良いので、まぁ目をつぶるしかないのもあるだろうということですね。

あとは、あ、これはですね、オーバーサンプリングというふうに呼ばれる方法です。 はい。 それをこう、ターンを使わなければ、ここに書かれているような内容ということですね。 だいたい男は社会調査に協力してくれづらいので、男の方は男を割と多めにサンプリングをしておいて、そうすると回収レベルで見ると、だいたい男女の分布が母集団の割合に沿った形で回収できるといったようなこともあります。 で、それが気持ち悪いんであれば、まあ事後的に、まあこの事後相関って話を前回お話ししたと思いますけれども、母集団の分布に合うように、まあ条律によって補正をする、ウェイトバックという方法ですけれども、それによっては補正をするということもあると。

で、えー、これは謝礼によって具体的にどんなバイアスがあるのか。 これはですね、私も興味があったので調べてみました。 マーサーという人たちの研究、パブリックオピニオンクォータリーだったかな？ 非常に有名な雑誌ですけれども。 えーと、えーの 2015年の論文で、要はこれはいくら出したら協力してくれるの？ っていうことを実験的に扱った研究です。 で、えーこの右側のパネルにですね、インパーソンが、これが訪問面接ですね。 メールがこれが郵送方法で、テレフォンがこれは電話調査ですね。 2015年なので、まだメール調査ってそんなに多くないわけですが。 で、プリペイドっていうのは謝礼を先渡しにするという場合どうなのかってことですね。 で、インパーソンとメールとテレフォンのプロミスっていうのは、これはプロミスなので、協力してくれたら謝礼を渡しますよという、まあ後渡しと呼ばれる方法ですね。 で、一般に社会調査法の中で知られているのは、謝礼は先渡しの方が回収率が上がるということが知られています。 まあ、いろんなメカニズムが考えられると思うんですけれども、先に渡しちゃった方が良い。 ただ先に渡すってことは、対象者全員分の謝礼を準備しなきゃいけないので、その分お金はすごくかかるということが、えーコストの問題があるんですけどね。

で、えーと一番ですね、回収率の上昇に寄与しているのは、あの上げないってところからちょっと上げるっていうところが、一番寄与しているというところですね。 なんか限界効用逓減の法則みたいなのが働いてるような感じに見えるような、きせん形があの推移を見せますね。 インパーソンプリペイドなんかでいうと、えーともうほとんど、うーん、どうでしょうね、 20ドル、20ドルの謝礼を渡すのも、まあ 40ドルの謝礼、 60ドルの謝礼って言って、まあその 0 から 20に行くまでのこの上昇分に比べると、まあその効用というものは随分下がってしまっているというものですね。 なので、高けりゃ高いほど良いのかというと、回収率に対してはそうとも限らないと。 何かを差し上げることの方が重要だということですね。 で、じゃあ謝礼の額とバイアスの関係はどうなのかというと、これはどうもはっきりしていない。 まあ、金銭的な動機が強いという、一種のパーソナリティとか、あるいは何らかの指向性みたいなの自体が、えー研究で着目する変数と強い相関を持っているような場合には、もしかすると何らこのバイアスが生じるのかもしれませんけれども。 あの、高額な謝礼だから、あの、それに引っ張られて参加するって人たちが入ってくること自体が、サンプルの構成に大きな影響を与えるというふうな結論は得られていない。 ので、まあ金があるんだったら、出すなら出したらどうですかと思いますが、まあこういう先行研究もですね、そんなに高いからといって、あの、要は線形に回収率が上がるかというと、そうとは限りませんよっていう研究の結果なんかを見ると、あの、まああんまりやりすぎてもしょうがないのかなというふうに思うというところですね。

はい。 で、あとはゲーミフィケーションについてのコメントですね。 ゲーミフィケーション、一応紹介しましたけれども、もちろん万能ではありません。 まあ、ちょっと画面に動きが出てくるので、なんかちょっと面白く楽しいかなっていうふうに思ってもらえることが期待できるし、そういう研究結果を報告する論文はいくつもあるんですけれども。 じゃあ、この授業でも取り上げたサティスファイシングがどうなのかとか、項目回答がどうなのかとか、回答時間がじゃあどうなるのか。 回答時間はゲーミフィケーションやった方が長くなるって言うんだけれども、それがその回答に真面目に答えてくれた結果、長くなってるのか、ゲームやってて楽しいからとか、反応を見てるのが楽しくて長くなってるのかっていうのはわかんないので、えーなんとも言えないっていうところもある。 少なくともゲーミフィケーションによって回答データの質が高まるという、そういう知見はあまり報告されていません。 で、えーこれもケースバイケースということになるんですけれども。 まあ、今まで分かっていることを踏まえると、多少回答意欲の維持を目的とするという程度にとどめた方がゲーミフィケーションは役に立つのかなと。

特に社会学者たちがやるような調査っていうとか、あるいは皆さんもしアンケート調査なんかやったことがあるんだったらば、やる側に立つとあれも聞きたい、これも聞きたいなんてどんどん質問増えるんですよね。 質問が増えると、さっきも見せた通り、見せたご紹介した通り、回収率は下がっていくので、えーそういう状況下で、まあ多少回答意欲、アテンションスパンを維持するっていう目的にとどめるのが、まあ今のところは妥当なゲーミフィケーションの強化なのかなと私自身は仮説的には思っています。 だから、あまり派手な演出とか、複雑なゲーム性みたいなものを調査に持たせてしまうと、それをやること自体が目的になっちゃったりすると、回答の質になんらかの影響が生じてしまうかもしれませんねということで、えーリライトしたいと思います。 はい。 で、本日の内容ですけれども。 データ収集の新時代、新時代と言ってもだいぶ時間が経ってきましたけれども、社会調査以外にもデータを集める方法はありますよねっていう話をしていきたいと思います。 今日はこれ多分終わらないと思うので、どこかキリのいいところで今日は切り上げたいというふうに思います。

で、前回のおさらいもいいんですけれども、本日はこの典型的な、今まで何回か紹介してきた統計的な社会調査の方法以外で注目されているビッグデータの活用、あるいは実験手技試験というよりは社会調査の中で実験的手法Survey ExperimentとかSurvey実験という風に呼んだりもしていますけれども、そういう方法について少しご紹介をしておきたいと思います。 

話者 1 24:31 
で、まずビッグデータのお話をしますけれども、このあたりのことはおそらく皆さんもっと詳しい機械学習等々に詳しい先生方の授業とかも取られていると思うので、極めて表層的な内容です。 で、サーベイ実験については、ちょっとこの授業の時間中というか、ちょうどそうですね、無作為割り当ての話をするあたりのところぐらいまで、あと 二三十分ぐらいまでの間にですね、このFormsからログインしていただいて、氏名と学籍番号を入力して回答送信するとURLが出てきます。 その URL から少し質問に回答していただけたらなというふうに思います。 私の話を聞きながら、この調査実験へのご協力をお願いできればというふうに思います。

はい。 で、まずビッグデータってやつですけれども、それは何だということですね。 ビッグデータって何かって考えると、皆さんそれぞれいろんなものを想起されるかもしれませんけれども、まあ今もう我々の日常生活の中に様々な形でビッグデータというものが埋め込まれているというか、溶け込んできていますね。 例えば、これは左側に書いてあるのが横浜市の児童生徒 26 万人の教育ビッグデータ活用会議実践フェーズのゴニョゴニョと書いてあって、恐らくこれは学校で取ったいろんなデータを。 なんか分析しますということなんですよね。 子供の心の子供の心をケアという、これはおそらく学校教育の日々のですね、いろいろ、まあたぶん日々の学校教育でいろんなデータを取っているので、そのデータをひとまとめにして分析するってことになるんですよね。 あとはこれ、僕全然去年知らなかったというか、ものなんですけど、カプセルホテルで睡眠データを取ると、その代わり結構安く泊まれるよみたいな。 そういうカプセルホテルがあるということですね。 えっと、どこだっけ？ 仙台かどこかで学会があったときに大学院生がなんか知り合いの先生と同じご飯を食べていたんですけれども、その先生が知っている大学院生がなんかいるって言うから、呼び出して酒飲ませたんですけどっていうことはあるハラっぽいですが、うまいもの食わしてやるからと言って呼び出したんですけれども。 で、どこに泊まってるの？ って言うと、なんかこういうなんか寝るとデータが取られる所に泊まってますとか言って、そんなとこいたくねえよっていうふうに思いましたけれども、その代わり安いんですよね。 だから睡眠時間とか、多分寝返りを何回打ったとか、あるいは覚醒したとか、そうすると多分いろんなものを取ってる。 その情報を取る代わりに安く泊まれるっていうようなカプセルホテルが最近はあるらしい。 そういうもので、いろいろ睡眠データからいろんなことを検証しよう。 当然泊まる人も。 なんか独占みたいなものも多分取っているんでしょうね。 そんなふうにもビッグデータが活用されているということですね。

なんかニュースか何かで筑波の何先生だったか名前を忘れましたけれども、ポケモンか何かのアプリか何かで睡眠データを取ったもので研究したものがネイチャー系の雑誌に載ったとかっていうのもなんか記事で見ましたけれどもね。 で、こういった何て言うか、あの、えっと、まさにデータを取りに行ってる系のものもありますけれども。 右側っていうのは皆さんも多分ソーシャルメディアを使われている方とか、そういうことでいろいろ書き込んだりされてる方もいらっしゃると思いますが、そういう SNS のデータを使って意見の分布とか言説の推移みたいなものを分析するといったようなこともよくやられていますね。 計算社会科学とか計算科学の中では、こういった SNS のデータというのは比較的取ってきやすいで、さすがに睡眠データとかはなかなか我々が簡単に取ろうと思っても難しいですけれども、アレックスとかそういうところからちょっとお金を払ってデータを取ってくるということは、そんなに難しい話ではないので、よくこういうふうに使われてますよね。 で、昨年、昨年ですよね、昨年じゃないか、昨年ごとじゃなくて一昨年ですか。 兵庫県知事選でいろんなでいろんな情報が流れたというところで、そのクラスタリングをしたような、そんなデータの活用の仕方もあるということで、今やビッグデータというのは様々な場面で活用されるようになってきています。 ビッグデータと並んで、近年 AI という言葉も本当に身近な言葉になりました。 で、これはもう数年前ぐらいの NHK スペシャルの番組ですけれども、我々もこの番組にデータを提供して商業分析しかされなかったから何だっていう風に思っちゃいましたが。 はい。 別にマツコ・デラックスさんと有働由美子さんが悪いわけじゃないんですけれども。 まあ。 このビッグデータと AI というのは当然違うものですね。 で、 AI っていうのは一種の何て言うかデータ解析の仕組みの総体というかですね、そういうものであって、主として機械学習、特にディープラーニングによって非常に複雑なデータの変数の組み合わせから様々なものをパターン化したりだとか、あるいは予測を行っていくという方法を実際に実践する、何というか、インフラというか、プラットフォームとか、そういう仕組みそのもののことも AI なわけですね。 で、その AI が解析するのが多くの場合ビッグデータということになります。 で、データを効率的に解析する必要があり、そのために機械学習の手法が役に立つというふうに言われているわけです。 あの、所詮なんか二十ケース三十ケースぐらいのデータであれば、別に私でだって電卓叩けばいろんなことができるわけですけれども、何十万何百万というデータを分析しようと解析しようとすると、場合によっては、あるいはその立てるモデルによっては、私が皆さんが今持ってらっしゃるようなラップトップのパソコンではとてもちょっと太刀打ちができない場合があったりもすると。 あるいは私のパソコンの中に入っているような統計解析予測という上ではあまりに時間がかかりすぎるという場合もあると。 そういうときに、こうした機械学習の手法、ディープラーニングの手法なんかを活用することで、効率的にデータを解析することができるということで、この AI とビッグデータの相性というのは非常に良いわけですね。

で、まあもう 2026年の今となってはわざわざこんな説明をする必要もないのかもしれませんけれども、要は機械学習って何をしてるの？ ということですが、今スライドに何かを載せています。 これは一体何だということです。 まあ、猫であると同時に、これはアビシニアンという猫の種類ですね。 私、好きなんですけれども。 じゃあこれは何であるかということを判断させるっていうときに、 AI はどうやってこの画像を何かして理解をするのか。 もしかすると猫という風に言うかもしれないし、もうちょっと荒っぽく動物って言うかもしれないし、もしくはいや、これはただのあのなんか本当の動物ではなくて、人形なんだとか、 ぬいぐるみがなんか精巧に作られてるだけなんだっていうふうに判断するということもあり得るわけです。 AI それ自体ですね。 じゃあ、どのようにして AI はこの画像から、あ、これは猫ですねというふうに言えるのかというと、基本的には人間が定義をするわけです。 まあ、いろんな動物がいるわけですけれども、その動物の中でこれは猫だね、これは猫じゃないねとか、これは犬だねとかこれは鳥だねとか、これはネズミっていうと悪いか、ハムスターだね、とかですね。 

話者 1 33:11 
っていうふうにラベル 付けをしてあげたデータを学習することによって、 AI はその次に学習されてないものが出てきたときに、きっとこれは確率的に猫だろうとか猫じゃないだろうということを判断するということですね。 で、そのような学習のために起きるデータのことを教師データというふうに一般に呼んでいるわけで。 もちろんその機械学習の方法の中には、その教師データを使わずに、もう端的に分類するだけということもあると思います。 この画像を見てですね、これが猫、猫なのか何なのかってことはラベル付けはしないけれども、とにかく似たもの同士をクラスタリングするってことは、いわゆる教師なし、教師データのない機械学習の方法でももちろん可能ですけれども、まあそれだけされても我々困っちゃうわけですよ。 実際にはそれが何であるかという意味づけまで行かないと我々の役には立たないので、そこは結局誰かがこれは猫ですよ、これは猫じゃないですよっていうことを判定する膨大な学習データを作った上で、その学習の結果として、次にここの映像に画像に出てきてないものがなんかポンっと出てきたときに、これは何ですか？

って言って、あ、猫だねというふうに考えることができるというわけです。 で、職業コーディングのお話をしたときなんかの、いわゆる職業コーディングの自動化っていう仕組みも基本的には同じです。 私のようなハンドコーディングで職業分類をした人間のデータを学習することによって、その癖は本当にいろんな人がコーディングした結果を多分読み込ませたらいいんでしょうけれども。 えーと、学習することによって、私がコーディングしてないようなケースについても一定程度、あの、私の正確さの範疇でというところで、こう職業コードというものを判定してくれる。 一定の確信度を持って判定してくれるというふうに応用することができるわけですね。

で、まあ本当に今画像検索って性能が本当に高まっているので、僕も本当に日常生活で活用する場面が多いですけれども。 まあ画像検索なんて、私が大学生の頃なんか画像検索って本当にひどいものでしたが、本当に今は性能が上がっています。 で、そういうものが今利用できるのは、まさに機械学習が発展してきたからだというふうにも言えるわけですね。

で、その機械学習によって学習され、場合によっては分析される、解析される。 ビッグデータっていうのは文字通りビッグなデータというわけです。 で、ビッグデータの定義っていうのは明確な定義が与えられてないって書いてあるんですけども、まあ、要は、いろんな定義の仕方があるということなんですけれども。 共通する特徴としては、次のような側面が挙げられています。 ボリューム、大容量であるということ。 で、バラエティに富んでいる、多様性があるということ。 ベロシティ、速度が凄まじいということですね。

つまり、IoTと呼ばれる我々の日常生活、いろんなものがデジタルデバイスを介してインターネットによってつながることによって、デジタルデータの発生や更新頻度が増大していきます。 だから、もう一秒一秒データが蓄積されているっていうような社会です。 社会というか、ビッグデータを言えば、もうそういうレベルですから。 非常にデータのサイズが大きい。 そういうものを効率的に解析していかないと手に負えないというわけですね。

で、データの性質による整理なんかもあるそうです。 データって言うからには、何かこう、いわゆるデータっぽいものも、ビッグデータっていうふうに考え、いわゆるデータっぽいものをビッグデータと考えるのが普通なのでなんですけれども。 この狭義のビッグデータに加えて、そういうデータの処理や蓄積や分析技術も含めて、つまりデータだけじゃなくて、その解析手法とはある種一体としてビッグデータを捉えるという見方もあるそうです。

で、とはいえですね、最終的には我々が機械学習によるものであれ、その他の方法によるものであれ、何らかの形でデータを解析するときには、このような構造化されたデータのフォーマットにしないと何もできないわけなんですね。

構造化されたデータというのは、データの形式があらかじめ決まっていて、ほとんどの場合数値の形式で所定のフォーマットに入力されていくデータのことを意味します。 買い物、お買い物なんかにちょっとジェンダーバイアスがかかっちゃってますけれども、お買い物なんかに行くと、レジ係の人が商品読み込んでくれて、最近はセルフでやる場合もありますけれども、セルフ商品をバーコードで読み込んで、何を買ったかというのをカウントしていってくれるわけですね。 で、実はその背後ではだいたい何時何分にどんな商品が購入されているのかっていうことが自動的に入力されていくわけですね。 日付、時間、それからおそらくはポストデータの中でもどのお店ってことである程度地域性というものも分かってきますし、忙しい時にはやらないんでしょうけれども、お店とか、あるいはポストのシステムによっては手動でですね、大体何歳ぐらいの何者なのかっていうことが個人特性のようなものも入力されたりする。 それが結び付けられることによって、いつどこで、どんな性別の何歳ぐらいの人がこういうものを買うんだということがわかってくる。 そうすると、そういうデータが蓄積されていくと、じゃあ30歳代の女性にはこれをもうちょっとお勧めするような商品開発をしようとか、というふうに、そういういろんな企画を立てる際の貴重な資料になっていくと。 情報になっていくということですね。

で、こういうふうにですね、何か新データを読み込ませていくと、自動的にマトリックスの中で指定のところにデータが勝手に入力されているようになっていくって言うのであれば、これは楽な話なんですけれども。 現実にはそんなデータばかりではないわけです。

ビッグデータというのはですね。 例えばソーシャルメディアの投稿内容というのはテキストですね。 で、あるいはそのソーシャルメディアの投稿内容がテキストなんだけれども、そのテキストの内容に対して、いろんな返信が付いたりしています。 まあ、ストリップと呼ばれるようなものも含めてですね。 いろんなその投稿内容の間の関係の情報だとか、あるいはソーシャルメディアであればフォローを、フォローをされる、フォローをするされるっていうような関係というものも情報としてはあるわけで。 そういう情報というのは最初から構造化されているわけではないわけです。 一定のフォーマットには従っているけれども、その生のデータをそのまま数量的な解析にかけるということは難しい。

ちゃんと。 その数量的な分析ができるようなフォーマットに直していかないといけないということですね。 あるいは画像とか音声とかデータだって、何らかの方法で構造化で構造化されたデータのフォーマットに変換しなければならないし、様々な位置情報についてもそうです。 で、これらは一定のルールに従って構造化されたり、ピクセルレベルで解析されたり、あるいは波長の形で解析されたりすることによって、データとして利用されるようになるというものです。 こういうデータの多くは、日々我々が知らない間に生成してしまっているもので、なかなかですね、こういうものを生み出さずに生活するというのは、なかなか難しい時代になってきているのかもしれません。 位置情報を記録しないように切っているという人もいるかもしれませんけれども。 

話者 1 42:09 
当然マップの情報でいろんなどこか、どこかに行ったりするときとかに、マップでいろんなところ場所を検索したりすることもあると思いますけれども。 そうすると、こいつは一体いつ、どんなところに行ってるんだなみたいなことがわかってくるわけなんです。 スマートフォンを持ってると、えー何年の何月の思い出みたいな、余計な情報をいろいろ出してきてくれたりすることもありますよね。 あの、しかもこの位置情報と、そのそこで撮った写真とかがですね、えー結びつけられる形で、えー紹介されてしまったりはするわけです。 まあ、あの、そういうのが楽しいって人もいるかもしれませんけれども。

えーまあそういうライフログと呼ばれる情報っていうものを、日々われわれは、えー、あのどんどん知らない間にですね、蓄積されて、それらはあのまあ主におそらくGAFAなどの、えーと、えープラットフォーム企業によって色々と分析されているんでしょうねというふうには思います。 で、えーまあ包丁も結局、まあ包丁や何でもそうなんですけれども、結局使う人間の意図によって道具とか技術っていうものは、まあ凶器にもなれば、えー人の役に立つすごくいい何かを生み出すものにもなり得るわけです。 で、エポックメイキングだったもの、SNS ってもしかすると結構やべえんじゃねえの？ というふうに人々が気づき始めた、まあ非常にこう象徴的な事件がケンブリッジアナリティカ事件と呼ばれるものです。 あの、えーこれはあのーなんていうのか、まあ一種のコンサルティング会社ですね。 えーイギリスのコンサルティング会社、ケンブリッジっていう名前があるのは何かケンブリッジ時代と関連がありそうなのかっていうふうにこう誤解しそうですもので、全然関係ないわけですね。 あの大体こういうふうに、なんかこう、あの、えー嘘にならない程度に、えーなんかこう有名大学とかの名前とか使っちゃうっていうあたりが、まあいかにもなんかコンサルテイアだなとかという風に思っちゃう瞬間なんですけれども。 えーと、まあいいコンサルもいるかもしれません、ちょっと。 で、あのケンブリッジアナリティカ事件というのがあって、これは2016年のアメリカ大統領選挙とか、えーあるいはイギリスは今 EU から離脱してしまいましたけれども、あのブレグジット、ブレグジットの国民投票の際に、その数千万人の FACEBOOK 利用者の情報を利用して、あのセグメンテーションを行っていたんですね。 で、ああいうあのまあFACEBOOK って結構ね、お年を召した方ばっかり使うので、あの皆さんは最近のFACEBOOK じゃないんだろうと思いますけれども。 えーまあなんかこう、SNS でバーッと流したりしてると、なんかクイズとかがあって、あのちょっと、ちょっとしたクイズとかが出てきて、あのつい自然に答えちゃったりするっていうようなことがまああるかもしれません。 私はやったことないですけれども。 ああいうクイズなどで利用者、そのクイズに答えた人の個人属性とか、あるいは政治的当派性とか趣味とか嗜好などをまあ収集すると。 えーつまりクイズに答えることによって、その答えた結果と、そのアカウントの人の、なんていうか投稿内容みたいなものを結びつけていくことによって、えーどういったあの普段どういった内容を発信している人が、まあどんななんていうかな、あの意識とか態度を持っているのかっていうことを、一見こうまさにゲーミフィケーションの形で情報を抜き取っていくということをやっていくわけです。 しかも、それを何か友人にも勧めるみたいな感じで、どんどん広がっていくことによって、ある意味ネットワークデータまで得られてしまうわけですね。 で、そのFACEBOOK では当時、今はどうか知りませんが、情報収集自体は規約違反ではないけれども、そこでケンブリッジアナリティカが得た情報を第三者に提供した疑いがかけられたということです。 具体的には、当時のこれ、トランプ政権第一期のときですね。 えーと、ヒラリー・クリントンと争った、大統領選を争ったときのトランプ陣営だとか、あるいはブレグジットの EU 離脱者離脱派へのデータ提供がなされたんじゃないかということで、えーまああの懸疑がかけられたわけです。 で、これはまさにマイクロターゲティングによるビッグデータだからできるものですね。 数千万人のデータだから、非常に細かい属性でターゲティングしたとしても、あの、かなり細かい組み合わせでグルーピングしたとしても、それなりの数のデータが残っていますから、ある程度統計学的に信頼できる、えー推計ができちゃうわけです。 それが何を代表しているのかっていうのはよくわかんないんですけれども。 ただ、あの統計学的には安定した推計は可能なので、これだけのデータであれば相当に細かいグルーピングをしたとしても、えーまあ多分何千何万というグループが残っているわけでしょうから、あの細かい細かい集計ができます。 で、それによって世論に介入したんじゃないかっていうのが、このケンブリッジアナリティカにかけられた権利だったんです。 例えば、えー民主党支持者に民主党候補者のスキャンダル記事を広告と称してFACEBOOK に流すとか、えー共和党支持者にはトランプを称賛する動画を広告として流すとかですね、そういったようなことが、お前らやってたんじゃないのということで疑われたわけです。

で、えーと、まあそういったことで、結局ケンブリッジアナリティカ廃業するんですけれども、あの、それだけですね、結構当時、10年前だと、一応しみじみしちゃいましたけれども。 えーと、そういうことなどがありました. ただですね、えーまあ一応ここは公平を期してケンブリッジアナリティカなんか見るからに怪しそうなんですけれども。 じゃあマイクロターゲティングをすると、世論がそんな簡単に変わっちゃうのかというと、ここはちょっと公平を期していっておくと、まあちょっと今の技術だとね、ディープフェイクがこれだけ発達しちゃうとなかなかまた状況変わるかもしれませんけれども、あのマイクロターゲティング。 モーティングの政治的効果については懐疑的な研究が多いです。 で、指摘されているのは、エコーチェンバーと呼ばれる効果は生じているというふうに言われています。 エコーチェンバーというのは、同じ意見の人々とのコミュニケーションを繰り返すことで、自分の意見が強化されるという現象です。SNS なんかで、例えば何か自分の好みのもの、好みのこととか趣味のことについてツイートした、あの、ポストしたりとかしてSNSに流れていくと、アルゴリズムがですね、こいつはこういう内容のことを発信するんだっていうことで、同じようなことを発信しているような人たちの投稿内容が流れ込んできやすいように、なんというかな、こう設定されているわけですね。 アルゴリズムが。 そうすると、SNSだけを見ると、世の中はみんなこれ好きなんだ、みんなこれに注目してるんだ、というふうに錯覚しやすくなってしまっていることによって、なおさら自分が思っていることとか、特にこれが今日はトンカツ食いましたみたいな話だと、世界中の人がとんかつ食ってるだろうとは思わないかもしれないけれども、これが誰それを支持しますとか 誰それには反対しますみたいな、まさに政治的な態度とか党派性に関するような投稿内容だと、なんか自分の周りからSNSに流れ込んでくる情報を持って、世の中みんな自分と同じ意見を持ってるんだというふうに思ってしまい、その結果、より自分は正しいというふうに思ってしまうようになるというのがエコーチェンバーと呼ばれる現象ですね。 

話者 1 50:18 
似たようなものにフィルターバブルと呼ばれるような現象もありますね。 これが自分のネット上での検索履歴等々から、これも結局帰結としてはエコーチェンバーといったような話になってくるんですけれども。 あの、何か自分の検索履歴からおすすめとして出てくるものが、だんだんと自分の好きなものとか自分の思考戦に近いものばかりが表示されやすくなっていくっていうようなことですね。 今、我々はもう本当にエコーチェンバーとフィルターバブルの世界を生きているっていうことを自覚した方がいいわけですね。

これをどうこうするっていうのはなかなか難しい話なんですが。 少なくとも、もう明らかにこの影響を受けて、我々今情報に接してるんだなということを自覚するかしないかは結構でかい話だと思います。 で、ビッグデータは非常に表層的な話をしてきましたけれども、ではそれと、この授業の中で取り扱っている社会調査というものの間にはどういう違いがあるのか？ ということですね。 ビッグデータというのは、多くの場合、集めようと思って集めているわけではなくて、日々のさまざまな活動によって知らない間にとは限らないけど、多くの場合はあえてデータを取ろうとしてデータを集めたものではなくて、例えば行政データであれば、何らかの別の目的で提出しなければならない書類だったりだとか、あるいはそういうものの届け出のデータが蓄積されていくことによってビッグデータ化するっていうこともあるだろうし、SNSにしたって、ああ、そうか、これはもうこの子使っちゃいけないのかもしれませんけれども。 あのー、何気ない投稿、何かちょっと発信したいなと思って投稿したものがデータになっていくとか、あるいは皆さんも何かいろんな、例えばマイナーとかがこの中にいるのかは知りませんけれども、飛行機乗るのが好きな人とかは、全日空とか日本航空とかのマイレージプログラムに入ってるかもしれませんが、そういうマイレージプログラムに入るためには顧客情報というか登録をしなければならないわけで、そのときの登録情報が蓄積していくことでデータ化していくわけです。 で、それが構造化データになる、変換されることによって数量的な分析が可能になるということですね。 これに対して社会調査というものは、最初からデータを集めようとして集めているということが大きな違いです。

対象者に向かって調査に協力してくださいという連絡を出して、やってもいいよというふうに言ってくれた人たちだけが回答してくれる。 だからこそ、回収率の問題とか、あのー、サンプリングバイアスの問題だとか、いろんな問題がカバレッジの問題とかいろんな問題が出てくるんですけれども 少なくとも調査をやっている側も、調査の対象になっている側も、この調査をやってるんだということについてはお互い了解済みであるというのが社会調査によるデータ収集の営みです。 これからすると、ビッグデータというのは多分対象になっているというか、データの客体になっている人たちは、まさかそれがデータとして解析されるっていうことは多分あまり意識してない人たちが多いと思います。

されるもんだということを前提にいた方がいいと思うんですけれども。 あの、はい、そこが大きな違いですね。 で、まあ近年ではこういういろんな行政データなんかもちょっとずつ使えるようにしてきているような動きも出てきている中で、わざわざ社会調査で何か調べることってもうやらなくてもいいんじゃないっていう人たちも出てきましたし。 えーと、ほんとこの 10年前ぐらいであればビッグデータと機械学習の方法さえあれば、伝統的な統計調査などは-で、いずれ消滅するよっていうふうに、まあたんかを切った研究者、日本人じゃないと思いますけど、海外ではいました。 まあしぶとく生き延びてますというふうに言いたいですけれども。 あのー、まあこの主張に対してはですね、まああの、私の飯の種がなくなるので反論せざるを得ないという点はあるんですけれども。 まあ確かにですね、我々が意識しないところでデータは蓄積されて商品化され、場合によってはあのー、何らかの形でですね、新しい何かを発見するというところで活用されるという点で、もちろんいい面もあるわけですし、えーと、一人一人のデータの価値は小さいわけです。

なんかちょっと数年前に、えっと、なんだっけ、レシートの、レシートを写真で撮って、えーと、それをアップロードして、それが貯まっていくと、ちょっと報酬になって帰ってくるみたいな、そういう仕組みみたいなものが、そういうサービスみたいなものがありましたけど、要はあれは家計調査みたいな話ですよね。 で、それは一人一人のレベルで見ると価値は小さいんだけれども、それが何十万というふうに塊になってくると、さっき言ったようなセグメント化した集計が可能になり、こういうライフスタイルの人はこういうものを買っているから、じゃあ次に商品開発するときにはこういったところに訴えかけようとかっていう発想が出てくるわけですね。 なので、データというのは蓄積されることによって価値がどんどん大きくなってくるわけです。 で、そういうビッグデータを活用すれば、人々の様々な消費傾向だとか社会的行動の実態解明も進むんじゃないか。 わざわざ調べなくたっていいだろう、もう人類学者の社会学者バイバイっていうふうに言われるっていうことは、まあまあ、なくはないというものですね。

えー、まあ確かにビッグデータもデータのサイズからすれば、我々が普段扱っているデータというのは数千人が関の山であって、場合によっては数百人のデータを使わざるを得ないような場合だってあるわけです。 そんなもんじゃ何もわかんないよというふうに言われるということもあるんですけれども。 今のところそれはまだちょっとラジカルな見方なんじゃないですかねというふうに、えー、まあ、あのビッグデータとか AI みたいなものが出てきたときに、ちょっとブームが、今もブームなのかもしれませんけれども。

えーと、それが出てきたときに、まあある意味ですね、もう社会調査なんていらねえよって言ってた人たちも、そういう啖呵を切るのも、ある意味自分たちのポジションを拡大していくためにポジションコプトとして行ってた部分は多分にあるでしょうというふうには思います。 で、当然ビッグデータですべてのことがわかるはずがないというか、ここに書いてあるようないわゆる統計的社会調査をやった人間であれば、なんかすぐに思いつくような疑問が出てくるわけです。

例えばビッグデータっていう SNS でデータを引っ張ってきましたって言うんですけれども、じゃあそれで何らかの統計解析をして、様々な特徴量をいろいろ計算して出してきましたって言ったときに、それって誰のこと言ってんの？ ってことはまあわからないです。 わからないし。 不問に付されてるわけですね。 あの、例えば今だと TWITTER、 X を使ってビッグデータ、ビッグデータ X からツイートの内容を引っ張ってきて、いろいろ分析しましたって言うけれども、えーと、あんな何て言うか、阿鼻叫喚の世紀末みたいな言論空間で物を今書きたい人って一体どんな人？ とかって。 まあ別にいいんですよ、皆さん撃って食べたものをアップロードするのはいいと思うんですけど。 えー、もちろん普通に投稿する人もいるけれども、少なくともアネクドートレベルでいろんな大学の先生たちたちの話を聞くと、今の若い人たちは自分からはあんまり書かない。 

話者 1 58:44 
余計ななんか絡まれたりするのがめんどくさいから。 まあ、ニュース戦、ロム、昔ロム戦なんて今でも言うのかしら。 えー、ロム戦が一番合理的な報道だっていうことが言われています。 じゃあ、そんな中でガンガンツイートしてる奴の言ってることを分析して、一体そこでわかった人たちっていうのは一体何なの？ っていうことについては、これがよくわかんないわけです。

えー、まあ結局これは何というか、帰結主義的に評価するわけで、結果論として評価していくしかないんですよね。 そこで言われていたことを、えー、と、我々が目にしてる現実を照らし合わせた時に、あってればあってたっていう風に言うけれども、違ってたとしてもそりゃそうだよねって話になるので、理論的な裏付けがやや怪しい。 まあもちろんですね、その、あくまでこの、例えばっていうバトルフィールドの中でのレスラーを自分は分析したいんだっていうことであればそれでいいんです。 そうであれば、母集団というか対象がきっちり定義されているわけですけれども。 そのビッグデータを使って日本人の意識について調べましたと言われると、うん？ という風になっちゃうということですね。

えー、うちの父親、母親は多分 X というものの存在すら知らないです。 私がアプリは絶対入れさせてないっていうことですね。 ろくなことにならないだろうからですね。 えー、目覚めちゃったりすると困るんでね、何かにね。

で、えーと、あと 二つ目。 まあ理由一っていうのは、母集団をちゃんと設計できるんですか？ っていう問題です。 で、二番目もこれも設計の話ですね。 調査をするというときには、何かを知りたくて質問を考えたり、実験の時にも何らかの測定方法を考えるわけですね。 で、その、あのー、何らかの概念に基づいて測定するための質問等を考えるのに対して、ビッグデータっていうのは、あの集まったものを事務的に解釈するしかないので。 えーまあ、あの、何でその、あの尺度を使うんですか？ 何でその測定メジャーメントを使うんですか？ っていうふうに聞かれたときに、まあどこまでそれを理論的に、えー、正当化できるのかっていうことがちょっと注意が必要と。 そこにある程度工夫、工夫というか、丁寧な議論をする必要があるだろうということです。

で、3つ目の理由は、これは次回お話ししますけれども。 えっと、研究倫理の問題です。 あのーデータが元になるのは多くの場合人間です。 ライフログとかSNSのデータも含めて、我々の活動の蓄積が分析されるわけですけれども。 社会調査の場合はさっき一応同意をもらった上で答えてもらうと言いましたけれども、皆さんが発信したソーシャルメディアで発信した情報というものが研究用に使われているかどうかということは、多分皆さん同意をした覚えはないと思います。

TWITTER X の内容を分析しましたとかいって仮に論文で出てきたとしても、自分は提供した覚えないぞという話になってくるわけです。 この中におそらく、あの利用規約のところに何かずらずらずらっとたくさん書かれている中で、おそらく免責事項があるんでしょうけれども、この点に関してどう考えるのかということ。 それから、オフラインとオンラインの世界の人間行動が、例えば人の意識とか態度みたいなもの、人間行動とか人間の態度を分析したいっていうのであれば、そこでオフラインとオンラインの人間行動が同じと仮定できるかどうかもそれもよくわからない。 ペルソナが分かれることってありますよね。 つまり、えーフェイストゥフェ、オフラインの世界がものすごく丁寧な、物腰穏やかな人が、オンラインの世界になった瞬間に、ものすごい暴れん坊になっちゃうっていうことがあって、これは可能性としてはあり得る。 人格を使い分けるっていうことは、あの、別に深刻なソシオパスやサイコパスじゃなくたって、十分あり得ることだろうというふうに思いますし。

えー、適切に設計された調査や実験であれば、別に何十万というデータじゃなくたって、ある程度の正しい結果を得ることは可能です。 これはどこかで紹介したと思いますけれども、あの、よほど細かい、よほど複雑な統計解析や集計をしたいということでなければ、えー標準誤差っていうのはもう数百ぐらいになると数千も数百も実は標準誤差のレベルってそんな変わらないんですよね。 それは 0.000000ぐらいのところでの違いというものが重要だっていうんだったならば、それはちょっともっと大きなデータじゃないといけないかもしれませんけれども。 内閣支持率が上がったか、下がったかってことを見たいぐらいだったら、あるいはそれが属性によってどう違うかぐらいを見たいんだったらば、別に何十万という人間のデータを扱う必要は特にないということですね。

はい。 で、えーここまではビッグデータのお話でございました。

ここからがもう一つの方法では、サーベイ実験と呼ばれるものなんですけれども。 えーと、ビッグデータはビッグデータで、近年ではそういう調査で得られたデータと、その調査の回答者がこれも同意を得られればですけれども、当初の調査の回答者が同意をすれば、例えばソーシャルメディアのアカウントとかを結びつけることで、えー調査データとビッグデータというものなんかをうまく結びつけるようなことだってできると思いますし、別にケンカをする必要は全くない。 お互いがお互いのいいところを補って、補い合っていければいいのかなというふうに私自身は思います。

で、えーと、このビッグデータに加えて、近年非常に急速に使われるようになってきているのがサーベイ実験。 統計調査の中に実験的な要素を取り込んでいくというものです。 で、これはウェブ調査とか、あるいはキャピのような方法が普及していったことによって、つまりペーパー＆ペンシルで行うような調査じゃなくて、コンピューターを使うということによって、サーベイ実験の実行可能性というものが飛躍的に向上しました。

なぜかというと、無作為割り当て、ランダムアサインメントと呼ばれる手続きが簡単に行えるようになったからですね。 紙の調査票でこの無作為割り当てというものを行おうとすると、実験群と処置群、実験群用の調査票と処置群用の調査票というものを 2種類作らなきゃいけないとか、それだから実験群というか、処置群は、しょち、処置群をえっと、実験群と処置群でしょ？ えっと、処置群が複数になる場合には、それだけ作らなきゃいけない調査票の数が種類が増えちゃうわけですね。 だけれども、コンピューター上であれば、そのランダムアサインメントするための乱数を発生させるプログラムさえ入れてしまえば、別に一種類のデフの調査表で何グループものグループを処置変数、処置群として分けて、処置群と統制群を分けることができるということです。

で、あのまあ、互いのコストが非常に安、あのー、コストをかけずに実験ができるようになった、あるいは複雑な実験ができるようになったというものです。 で、ここで言うのは無作為割り当てというものは、えー、これ何かってことなんですけれども。 これは心理学の、あるいは実験心理学とかの授業を取れば多分丁寧な解説があると思いますけれども。 あの、我々が今まで見てきたような社会調査のデータというものは、まあ観察データというふうに呼ばれることもあります。 で、観察データっていうのは、まああの、別に郵送法であっても観察データって言うんですけれども。 まあ実際には何て言うのかな、研究者の側が何の操作とか介入も行わずに、えー、返ってきた回答をそのままデータとして分析するというような類いのデータのことです。 

話者 1 01:07:26 
で、こういう観察データというのは当然利点があります。 利点は、調査企画者が知りたいことを直接尋ねることによって調べられると。 だけれども、観察データでは因果関係を知るということには限界があります。

で、社会科学における因果の推論、因果的な効果を取り出すという、まあCausal Inferenceというふうに呼ばれてますけれども。 因果推論は非常に長い間課題であり続けていて。 で、あの経済学もそうだし、社会学もそうなんですけれども。 観察データを使って、いかに因果推論をやるかってことで、やたらめったら複雑なモデルなんかも提案されるようになってきてるということですね。 で、えー、まあ、あの、因果関係をちゃんと取り出したいのであれば、えっと、実験すればいいって話なんですけれども。 数千人、数万人を相手に実験室実験をやるっていうのは、どう考えても現実的ではないわけです。 だし、特に社会学者なんかは、社会の縮像を描くっていうことも当然目的の中に入ってくるので、社会全体を代表するデータを得る必要がある。 そのためには、どうしても確率抽出、無作為抽出法が必要になってきてしまうんですね。 なので、えー、人文社会系で、特にデータ関係、データを扱う分野では、まあ社会学者は無作為抽出にこだわるし、心理学者も無作為割り当てにこだわるし、えー、経済学者が推定、識別というモデルの識別というものにこだわるという点で、三者三様、結構こだわるところが違うということですね。

えー、だからまあ経済学者と心理学者と社会学者が揃って、あの、あれこれ言い出すと百点満点のことをやんなきゃいけなくなるから結構大変なんですけれども。 あの、えー、まあそのようなですね、状況で社会学者は無作為抽出にはこだわってきたんだけれども、あんまり因果を考えるってことについては、まあ相対的に手薄だし、どちらかというと遅れてきた分野であったりしまう。

社会学についてはですね。 で、ただ近年、この因果推論に関する統計手法の開発というものも進んできまして。 特に実験によって、えー、因果推論できるんじゃないかという人たちも増えてきた。

で、このウェブ調査を応用しながら実験項目を実装する研究が増加していて、だから最近は社会学の研究者、若手の研究者なんかででも、無作為抽出標本を得るということよりは、まあ調査会社のモニターを使ってサーベイ実験をやるっていう方が、まあなんか安くデータも手に入るし、実験だからなんかちょっとファンシーなので、なんか査読にも乗りやすいなみたいな感じで、おいそれとこう論文書いてるって人もいるんですが。 私が査読者に当たると残念ながらっていう感じですね。

別に私実験嫌いなわけじゃないんですけれども、あの、実験はデザインが全てなので、なんかこうランダムアサインメントしたぐらいで論文は通ると思うなよっていう感じで査読をしちゃうという感じです。 で、ちょっと話を戻して、なんで観察データでは因果推論ができないのか。 まあ根本的にはできないんです。 あの因果にできるだけ近づくっていう努力をしてるってだけで、根本的には因果は分かりません、観察データでは。

言っちゃっていいかな？ まあいいや。 私はできないと思っています。 で、ちょっと例として、エリート大学に進学すれば金持ちになれるかどうか。 まあ金持ちって何？ とかエリート大学って何？ っていうのは一旦置いといてですね、このエリート大学に進学するということを因果推論的な言葉で言えば、処置変数treatment variableというふうに呼んだりします。 で、その結果、仕事による得られる収入のことをアウトカムというふうに呼んだりします。 で、エリート大学への進学による収入への処置効果というのは、このエリート大学に通った人の所得の期待値、まあ平均ですわな、から、エリート大学じゃない大学に通った人たちの、えー、所得の平均値、期待値を聞いてあげれば、処置効果がわかるということになるわけです。 で、この時のエリート大学進学群のことを処置群とかtreatment groupとか言いますし、行かなかった人たちは構成群、コントロールグループというふうに呼ぶわけです。 で、まあ、これ自体は、もう検証する必要のないような命題なので、大して面白くもないわけなんですが。 では、じゃあエリート大学に進学すれば、そうじゃない人よりも、あるいはそうじゃない人っていうよりは、エリート大学に進学した人が、もししなかったらどうなったでしょうかという命題、あるいはエリート大学に進学しなかった人が、もし進学していたらどうなっていたでしょうかっていうことを考えると、途端に話が難しくなってくるわけです。

人間、人生をやり直すことは、一応、あの、同じ時間での人生をやり直すことっていうのはできないので。 えー、まあ--あの、そこが観察データにおける因果推論の根本問題になってくるわけですね。 つまり、皆さんは今、この今、今の年齢とか今のライフステージで、今この東大にいるわけですけれども。 年齢もライフステージも全く同じ状態で、他の大学に行っているっていう人生は残念ながら実現することができません。 なので、もし皆さんが東大に進学していなければどうなっていたかということは観察しようがないんですよね。 なので、観察データでは因果の問題というものは原理的にはわからないということになります。

これをもう少し一般化して言うと、交絡と呼ばれる問題に我々は直面するので、因果関係がわからないということです。 ある初値変数とわいの間に因果関係と言えるためには、x以外の条件が等しいと言えなければならないわけです。 つまり、両者の間でアウトカム変数わいの期待値が違いがあるというのは、それは初値変数の値の違いだけですよと言える状況が伴っていないといけないわけですけれども。 でも、世の中そんな単純じゃないわけですね。 エリート大学に進学できるということは、同時に様々な別の変数の値も決定しているわけです。

いろんなものがあります。 親の学歴もあるだろうし、世界の年収っていうものもあるだろうし、生まれた場所も関係あるかもしれません。 し、それまで出会った人がどういう意識とか、どういう人と出会ってきたかということも影響するかもしれません。 で、そういう様々な別の変数の値も同時決定的なわけであって、そのと同じようにぜっともわいと関連しているという場合には、一見するとエリート大学にいる、行くことによって金持ちになれるという傾向が見られるんだけれども、それは本当にエリート大学に進学したものなのか、それともそこでは観察されていない別の要因によるものなのかがわからないという問題に直面します。 で、この時のぜっとのことを交絡変数というふうに呼びます。 もしですね、このわいからえっくすへの影響、このエリート大学に進学することで収入が高いんだということが、この交絡変数によって説明されてしまう場合は、えっくすの効果というのはあくまで見かけのもの、疑似的なものだというふうに考えざるを得ないということです。

で、そう考えると、じゃあ調査で交絡変数となりうるようなものをちゃんと調べて統制してあげればいいじゃないかということは、これは多くの研究者たちが考えること。 交絡変数ぜっとの値は条件付けることで、ぜっとの影響を除去したえっくすの初値効果を得ることはもちろんできます。 さっき言った親の所得とか学歴とか、あるいは幼少期の発達状況とかっていうものも例として考えられますけれども、じゃあ、この交絡変数を調査で調べれば因果効果がわかるんですか？ というと、やはりそんな単純な話ではないわけです。 

話者 1 01:16:09 
なぜかというと、交絡変数なんて無数にあるわけですから、どこまで調べれば十分に交絡効果というものをコントロールできるのかなんてことはわからないことが多いわけですね。 だから、どこまでいっても、なんかまだ観察されていない交絡要因の影響があるんじゃないだろうか？ という疑念がつきまとってしまうわけです。 なので、観察データは最大限因果的な効果に近づくことはできるけれども、因果効果を得ましたというふうに言い切ることまでは実際にはできません。

で、因果効果を得ましたっていうふうに主張しているような論文、まあもちろんありますけど、それはあの、その研究で使っている交絡変数で十分に統制できていると私は仮定していますという仮定の上での議論なんですね。 あとはそれを論文をレビューする人とかが、まあまあこれで十分かなと思うかどうかっていう判断の問題なので、デザインとして因果効果が取り出せているかどうかは結局わからないわけです。 で、こうした交絡問題に対して一定の解決方法を生み出すのが無作為割り当てということになります。 初値群の割り当て、初値変数の割り当てを無作為にしてしまうことによって、その初値変数の値状態が異なること以外は、他のグループの間で交絡が発生していないという状況を創出することによって、初値変数の因果的な影響というものを推定することができるようになるということですね。 ただですね、じゃあ無作為割り当て、何でもやればいいだろうというように考えたくなるんですけれども、無作為割り当ても社会調査の場合では必ずしも万能薬ではないわけです。 弱点は何かというと、割り当てられるものでないと無作為割り当てはできない。 当たり前っちゃ当たり前ですが、生まれをコントロールすることはできませんね。 皆さんがどこの家に生まれたか、生まれた瞬間に引っぺがして、別の親にぽやっと取り替えるようなことなどは、無作為にやるってことは、まあできませんわね、ということになっているわけです。

親をランダムに割り当てることはできないし、あるいは本人の学歴、さっき言ったエリート大学に行くか行かないかっていうところで、学歴を無作為割り当てするっていうわけにもいきませんわね、ということです。 で、しかもその学歴を無作為割り当てした場合、えっと、ね。 世界が変わってしまうので、世界の前提条件が変わった中で学歴というものが持つ意味自体も変わってしまうので、もはや実験の意味すらなくなってしまうという問題があったりもします。 だから、無作為割り当てができるのは、あくまでランダムに値を割り当てられるようなものだけということになります。

社会調査の中ではですね。 ということで、えー、あの、我々が調査の中で行うときには、何らかの情報を提示する、提示する群としない群、あるいは情報を提示しないというコントロールグループと情報を A を提示するグループと、情報 B を提示するグループということに分けて分析をするということが、実験をするということが非常に多いわけです。 最もシンプルなものは、一つの処置群と一つの統制、統制群は必ず準備するわけですけれども、一つの処置群と一つの統制群を準備する場合が最もシンプルなもので、例えば処置群には文章などの特定の情報を示して、統制群には何も示さないというものです。 で、情報を示した後で何らかの意見や態度を尋ねて、統制群と比べて処置群というものがどれぐらい意見のグループとか平均値が変わっているのかということを探るということです。

で、処置群と統制群への割り当てがランダムに決まっているのであれば、アウトカムの差というものは、情報を示したか否か以外には、以外のものとは解釈できないんですね。 あの処置変数の違い以外でアウトカム変数の差は解釈できないので、この処置効果というものは因果的だというふうに言えるわけです。

で、今回は冒頭で回答していただいたのはシンプルな実験の例でありまして。 つい最近起こった大事件をトリートメントとして設定をしてみました。 ベネズエラの大統領が拉致られたという事件ですけれども、とんでもない時代になったなというふうに思うんですけれども。 これについて皆さんにちょっと実験にちょっとご協力をお願いしたというのが、冒頭のスライドでお示しした。

ものでした。 一問だけ回答していただいたと思いますけどね。 えー、百十五人回答してくれている。 えーと、ちょっとこれでね、多分統計を見てもね、平均値わかんないと思うんですが。 えーと、はい。 実は三つ条件を設けていたんですね。 この一番左側っていうのが、これがコントロールグループです。 まあ、あの事実というか、一番シンプルなものですね。 マドゥロ大統領を連行しましたというものですね。 これが不当だと思うか、それとも正当だと思うか、それとも不当だと思うかというので。 どちらかといえば不当であるというのが一番多くて、次に多いのは不当であるというやつですね。 そういうものでした。

で、真ん中がですね、これはどちらかというとアメリカそんな悪くないんじゃないの？ っていう印象を与えるための処置をずっとやってみました。 連行されましたの後に、マドゥロ大統領は同国での独裁が批判をされ、ベネズエラベネズエラ国民の中には独裁政権からの解放に対する期待の声もあります。 これは一応ロイターか何かの記事か何かから引っ張ってきたということです。 どれだけの人が支持しているのかは知りませんけどね。 この独裁政権からの解放ですね。 あなたはアメリカ合衆国によるこの攻撃が正当だと思いますか、それとも不当だと思いますか？ ということに対して、どちらかといえば正当であるという人たち、人の割合がちょっと増えたって感じですかね。

ちょっと平均値とか見れてないんですけども、不当であるというのがちょっと増えてますが、このどちらかというのは正当であるという割合がちょっと増えてますね。 で、一番左側が、これがアメリカ、ちょっとまずいんじゃないのという情報処置、情報トリートメントを含めています。 今回の攻撃に対しては、国際法違反であるという懸念が、国連事務総長をはじめ複数の国連加盟国から表明されていますという情報をつけています。 こうすると。 少なくとも独裁、独裁の話をと比べると、正当だと答えている人たちの数はちょっと減っているということと、あとはトリートメント、コントロールグループと比べると、不当であると回答している人の数が増えていると。

ちょっと平均値とか後で見てみようかなというふうに思いますが。 えーと、分布を見ると、今回はちょっとうまく実験成功したかなという気がしなくはないです。 ちょっとね、人が拉致られているのに実験の題材にしちゃうっていうのは申し訳ないなと思うんですけれども。 過去何回もやるんですよ。 大体私、実験設計する時失敗するんで、今回こそは有意差が出てほしいと思う題材が出てくる。 これをネタになるって思ったんですけどね。 えーすいません。 で、こういったようなことを行うということになります。 で、えー、はい。 これが一番シンプルな無作為割り当て実験の例ということですね。 情報を特定のグループに与えて、特定のグループに与えない。 それによって質問への反応がどう変わってくるかということを調べる。 というのが社会調査、特に意識とか態度に関する研究、社会意識とか社会的態度について研究するようなグループではよくやられたりするものであったりします。 

話者 1 01:25:05 
まあ、言ってしまえば、質問票を作成するときに誘導質問とかはやっちゃダメですよとか言ったようなことをちょっと説明したかと思いますが、あれをわざとやっているということですね。 わざと特定の情報を与えて、どうそれで態度が変わるかどうかということを見る。 まあ、もし先ほどちょっと度数分布だけ言いましたけれども、もしこれが平均値のレベルでちゃんと有意差が出ていれば、まあメディアの報道にしても、何にしても、どういう情報をどういう切り口から語るかによって物事の見え方って大きく変わりうるんだなということが実感できる話でもあるだろうし、こんな感じでサーベイ実験というものを行うことが、しかもウェブ調査を使えば、いとも簡単に乱数を発生さえさせれば、いとも簡単に、あの、この情報トリートメント実験ができるというものです。

はい。 で、もう少し複雑なものとして、あとビネット実験と呼ばれるものと、えーと、ビネット実験と呼ばれるものと、コンジョイント実験と呼ばれるものと、あと理想実験とかアイテムカウント法と呼ばれる方法があるんですけれども、このあたりはちょっとまたいろいろ込み入っているので、次回お話をしたいかなというふうに思います。 で、それを知らなくても今回の課題は答えられるようにしておきました。 ビッグデータのことですね。 研究やビジネスの世界で、将来的に調査データとビッグデータをどのように組み合わせる、あるいは相互補完的に活用していくことができるか。 調査なんて ？ 
